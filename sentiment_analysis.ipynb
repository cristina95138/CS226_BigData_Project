{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/cristinalawson/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- geo: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+------+\n",
      "|                text|                 geo| brand|\n",
      "+--------------------+--------------------+------+\n",
      "|Just random felt ...|                null|adidas|\n",
      "|There’s a huge de...|                null|adidas|\n",
      "|ad: adidas Ultra ...|                null|adidas|\n",
      "|I love the way ad...|                null|adidas|\n",
      "|• adidas supersta...|                null|adidas|\n",
      "|@Mizuno @Mizunoru...|{'place_id': '821...|adidas|\n",
      "|• adidas supersta...|                null|adidas|\n",
      "|Ad: The OS Sale i...|                null|adidas|\n",
      "|Day 8 of #adiVent...|                null|adidas|\n",
      "|that damn adidas ...|                null|adidas|\n",
      "|@NERDvsGAMES @Xbo...|                null|adidas|\n",
      "|https://t.co/3HgQ...|                null|adidas|\n",
      "|Hey @adidas , me ...|                null|adidas|\n",
      "|@StrengthEwa What...|                null|adidas|\n",
      "|As someone who ha...|                null|adidas|\n",
      "|They are some cut...|                null|adidas|\n",
      "|adidas Originals ...|                null|adidas|\n",
      "|Keep those feet d...|                null|adidas|\n",
      "|Adidas Ultraboost...|                null|adidas|\n",
      "|Adidas Rivalry Lo...|                null|adidas|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from afinn import Afinn\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "af = Afinn()\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df.drop(\"_c0\")\n",
    "    df = df.drop(\"_c3\")\n",
    "    df = df.drop(\"_c4\")\n",
    "    df = df.drop(\"_c5\")\n",
    "    df = df.drop(\"_c6\")\n",
    "    df = df.drop(\"_c7\")\n",
    "    df = df.withColumnRenamed(\"_c1\", \"text\")\n",
    "    df = df.withColumnRenamed(\"_c2\", \"geo\")\n",
    "    df = df.withColumnRenamed(\"_c8\", \"brand\")\n",
    "    df = df.filter(df.text != \"text\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# text classification\n",
    "def polarity_detection(list):\n",
    "    total = 0\n",
    "\n",
    "    polarity_scores = [sid.polarity_scores(text) for text in list]\n",
    "\n",
    "    return polarity_scores\n",
    "\n",
    "def sentiment_detection(list):\n",
    "    total = 0\n",
    "\n",
    "    sentiment_scores = [af.score(text) for text in list]\n",
    "\n",
    "    return sentiment_scores\n",
    "\n",
    "def text_classification(words):\n",
    "    # polarity detection\n",
    "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
    "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
    "    # subjectivity detection\n",
    "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
    "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
    "    return words\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # create Spark session\n",
    "    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
    "\n",
    "    # read the tweet data from socket\n",
    "    adidas_df = spark.read.csv(\"Data/Preprocessed Tweets/adidas_p.csv\", multiLine=True)\n",
    "    asos_df = spark.read.csv(\"Data/Preprocessed Tweets/asos_p.csv\", multiLine=True)\n",
    "    boohoo_df = spark.read.csv(\"Data/Preprocessed Tweets/boohoo_p.csv\", multiLine=True)\n",
    "    chanel_df = spark.read.csv(\"Data/Preprocessed Tweets/chanel_p.csv\", multiLine=True)\n",
    "    gucci_df = spark.read.csv(\"Data/Preprocessed Tweets/gucci_p.csv\", multiLine=True)\n",
    "    hm_df = spark.read.csv(\"Data/Preprocessed Tweets/h&m_p.csv\", multiLine=True)\n",
    "    nike_df = spark.read.csv(\"Data/Preprocessed Tweets/nike_p.csv\", multiLine=True)\n",
    "    shein_df = spark.read.csv(\"Data/Preprocessed Tweets/shein_p.csv\", multiLine=True)\n",
    "    victoriassecret_df = spark.read.csv(\"Data/Preprocessed Tweets/victoriassecret_p.csv\", multiLine=True)\n",
    "    zara_df = spark.read.csv(\"Data/Preprocessed Tweets/zara_p.csv\", multiLine=True)\n",
    "\n",
    "    # Preprocess the data\n",
    "    adidas_df = preprocess(adidas_df)\n",
    "    asos_df = preprocess(asos_df)\n",
    "    boohoo_df = preprocess(boohoo_df)\n",
    "    chanel_df = preprocess(chanel_df)\n",
    "    gucci_df = preprocess(gucci_df)\n",
    "    hm_df = preprocess(hm_df)\n",
    "    nike_df = preprocess(nike_df)\n",
    "    shein_df = preprocess(shein_df)\n",
    "    victoriassecret_df = preprocess(victoriassecret_df)\n",
    "    zara_df = preprocess(zara_df)\n",
    "\n",
    "    adidas_df.printSchema()\n",
    "    adidas_df.show()\n",
    "\n",
    "    # text classification to define polarity and subjectivity\n",
    "    listValues = adidas_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    adidas_polarity = polarity_detection(listValues)\n",
    "    adidas_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = asos_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    asos_polarity = polarity_detection(listValues)\n",
    "    asos_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = boohoo_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    boohoo_polarity = polarity_detection(listValues)\n",
    "    boohoo_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = chanel_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    chanel_polarity = polarity_detection(listValues)\n",
    "    chanel_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = gucci_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    gucci_polarity = polarity_detection(listValues)\n",
    "    gucci_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = hm_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    hm_polarity = polarity_detection(listValues)\n",
    "    hm_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = nike_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    nike_polarity = polarity_detection(listValues)\n",
    "    nike_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = shein_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    shein_polarity = polarity_detection(listValues)\n",
    "    shein_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = victoriassecret_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    victoriassecret_polarity = polarity_detection(listValues)\n",
    "    victoriassecret_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    listValues = zara_df.select(\"text\").rdd.flatMap(lambda x: x).collect()\n",
    "    zara_polarity = polarity_detection(listValues)\n",
    "    zara_sentiment = sentiment_detection(listValues)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Brands': [\"Adidas\", \"Asos\", \"Boohoo\", \"Chanel\", \"Gucci\", \"H&M\", \"Nike\", \"Shein\", \"Victoria's Secret\", \"Zara\"],\n",
    "        'Sentiments': [adidas_sentiment, asos_sentiment, boohoo_sentiment, chanel_sentiment, gucci_sentiment, hm_sentiment, nike_sentiment, shein_sentiment, victoriassecret_sentiment, zara_sentiment]\n",
    "        })\n",
    "    ax = sns.barplot(x=\"brands\", y=\"sentiments\", data=df)\n",
    "    ax.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}